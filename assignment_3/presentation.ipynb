{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# SC: https://medium.com/geekculture/introduction-to-convolutional-neural-network-with-tensorflow-and-keras-cb52cdc66eaf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import copy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 50000, test size: 10000\n"
     ]
    }
   ],
   "source": [
    "# image dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "# min-max normalization\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "print(f\"train size: {len(train_images)}, test size: {len(test_images)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check how images look\n",
    "IMG_INDEX = 112\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "\n",
    "plt.imshow(train_images[IMG_INDEX] ,cmap=plt.cm.binary)\n",
    "plt.xlabel(f\"label: {class_names[train_labels[IMG_INDEX][0]]}\")\n",
    "plt.title(f\"image {IMG_INDEX}\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# \"A common architecture for a CNN is a stack of Conv2D and MaxPooling2D layers followed by a few densely connected layers.\"\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/\n",
    "#  ReLU activation function, is perhaps the most common function used for hidden layers. It is common because it is both simple to implement and effective at overcoming the limitations of other previously popular activation functions\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,570\n",
      "Trainable params: 122,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.4895 - accuracy: 0.4554 - val_loss: 1.2353 - val_accuracy: 0.5567\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.1491 - accuracy: 0.5923 - val_loss: 1.1062 - val_accuracy: 0.6067\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.0023 - accuracy: 0.6489 - val_loss: 1.0046 - val_accuracy: 0.6526\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.8968 - accuracy: 0.6875 - val_loss: 0.9143 - val_accuracy: 0.6816\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.8171 - accuracy: 0.7123 - val_loss: 0.8789 - val_accuracy: 0.6947\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "history = model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.8789 - accuracy: 0.6947 - 1s/epoch - 4ms/step\n",
      "accuracy: 0.6947000026702881\n"
     ]
    }
   ],
   "source": [
    "est_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"accuracy: {test_acc}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 30, 30, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 15, 15, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 290,186\n",
      "Trainable params: 290,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# let's check if ioncreasing filters will increase performance of the model.\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3, 3)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 1.4612 - accuracy: 0.4669 - val_loss: 1.1872 - val_accuracy: 0.5830\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 1.0697 - accuracy: 0.6205 - val_loss: 1.0367 - val_accuracy: 0.6358\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 40s 25ms/step - loss: 0.9086 - accuracy: 0.6817 - val_loss: 0.9160 - val_accuracy: 0.6842\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 0.8034 - accuracy: 0.7179 - val_loss: 0.8715 - val_accuracy: 0.7034\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 0.7240 - accuracy: 0.7458 - val_loss: 0.9055 - val_accuracy: 0.6929\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1f0182058a0>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.9055 - accuracy: 0.6929 - 2s/epoch - 7ms/step\n",
      "accuracy: 0.6929000020027161\n"
     ]
    }
   ],
   "source": [
    "est_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"accuracy: {test_acc}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-1, -1, -1, ..., -1, -1, -1])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([num[0] if num == 0 else -1 for num in train_labels])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[6],\n       [9],\n       [9],\n       ...,\n       [9],\n       [1],\n       [1]], dtype=uint8)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "now check 1 vs all for each class."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.2367 - accuracy: 0.9121 - val_loss: 0.1929 - val_accuracy: 0.9251\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.1869 - accuracy: 0.9304 - val_loss: 0.1716 - val_accuracy: 0.9344\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.1654 - accuracy: 0.9396 - val_loss: 0.1553 - val_accuracy: 0.9412\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.1495 - accuracy: 0.9460 - val_loss: 0.1489 - val_accuracy: 0.9463\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.1362 - accuracy: 0.9492 - val_loss: 0.1495 - val_accuracy: 0.9432\n",
      "313/313 - 1s - loss: 0.1495 - accuracy: 0.9432 - 1s/epoch - 4ms/step\n",
      "0: airplane; accuracy: 0.9431999921798706\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 20s 12ms/step - loss: 0.1946 - accuracy: 0.9281 - val_loss: 0.1428 - val_accuracy: 0.9459\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.1233 - accuracy: 0.9540 - val_loss: 0.1062 - val_accuracy: 0.9596\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.0974 - accuracy: 0.9648 - val_loss: 0.0965 - val_accuracy: 0.9660\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.0803 - accuracy: 0.9721 - val_loss: 0.0911 - val_accuracy: 0.9667\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.0670 - accuracy: 0.9765 - val_loss: 0.0973 - val_accuracy: 0.9659\n",
      "313/313 - 1s - loss: 0.0973 - accuracy: 0.9659 - 1s/epoch - 4ms/step\n",
      "1: automobile; accuracy: 0.9659000039100647\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.2846 - accuracy: 0.8996 - val_loss: 0.2563 - val_accuracy: 0.9011\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.2380 - accuracy: 0.9130 - val_loss: 0.2305 - val_accuracy: 0.9129\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.2173 - accuracy: 0.9198 - val_loss: 0.2172 - val_accuracy: 0.9219\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.2004 - accuracy: 0.9235 - val_loss: 0.2094 - val_accuracy: 0.9225\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.1867 - accuracy: 0.9297 - val_loss: 0.2125 - val_accuracy: 0.9222\n",
      "313/313 - 1s - loss: 0.2125 - accuracy: 0.9222 - 1s/epoch - 4ms/step\n",
      "2: bird; accuracy: 0.9222000241279602\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.2849 - accuracy: 0.9001 - val_loss: 0.2621 - val_accuracy: 0.9000\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 20s 12ms/step - loss: 0.2559 - accuracy: 0.9004 - val_loss: 0.2491 - val_accuracy: 0.9034\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.2405 - accuracy: 0.9045 - val_loss: 0.2365 - val_accuracy: 0.9091\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.2281 - accuracy: 0.9093 - val_loss: 0.2393 - val_accuracy: 0.9070\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.2127 - accuracy: 0.9151 - val_loss: 0.2233 - val_accuracy: 0.9134\n",
      "313/313 - 1s - loss: 0.2233 - accuracy: 0.9134 - 1s/epoch - 4ms/step\n",
      "3: cat; accuracy: 0.9133999943733215\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.2747 - accuracy: 0.8996 - val_loss: 0.2459 - val_accuracy: 0.9000\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.2365 - accuracy: 0.9092 - val_loss: 0.2864 - val_accuracy: 0.8722\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.2104 - accuracy: 0.9177 - val_loss: 0.2009 - val_accuracy: 0.9199\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.1884 - accuracy: 0.9274 - val_loss: 0.1851 - val_accuracy: 0.9286\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 20s 12ms/step - loss: 0.1713 - accuracy: 0.9331 - val_loss: 0.1917 - val_accuracy: 0.9226\n",
      "313/313 - 1s - loss: 0.1917 - accuracy: 0.9226 - 1s/epoch - 3ms/step\n",
      "4: deer; accuracy: 0.9225999712944031\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.2586 - accuracy: 0.9058 - val_loss: 0.2153 - val_accuracy: 0.9152\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.2146 - accuracy: 0.9183 - val_loss: 0.2079 - val_accuracy: 0.9229\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.1979 - accuracy: 0.9237 - val_loss: 0.1911 - val_accuracy: 0.9253\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.1858 - accuracy: 0.9289 - val_loss: 0.1948 - val_accuracy: 0.9236\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.1702 - accuracy: 0.9371 - val_loss: 0.1800 - val_accuracy: 0.9309\n",
      "313/313 - 1s - loss: 0.1800 - accuracy: 0.9309 - 1s/epoch - 4ms/step\n",
      "5: dog; accuracy: 0.930899977684021\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 23s 14ms/step - loss: 0.2309 - accuracy: 0.9114 - val_loss: 0.2079 - val_accuracy: 0.9229\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.1669 - accuracy: 0.9363 - val_loss: 0.1425 - val_accuracy: 0.9456\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.1435 - accuracy: 0.9456 - val_loss: 0.1345 - val_accuracy: 0.9478\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.1258 - accuracy: 0.9525 - val_loss: 0.1308 - val_accuracy: 0.9527\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.1143 - accuracy: 0.9570 - val_loss: 0.1237 - val_accuracy: 0.9544\n",
      "313/313 - 1s - loss: 0.1237 - accuracy: 0.9544 - 1s/epoch - 4ms/step\n",
      "6: frog; accuracy: 0.9544000029563904\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.2324 - accuracy: 0.9198 - val_loss: 0.1866 - val_accuracy: 0.9312\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.1633 - accuracy: 0.9429 - val_loss: 0.1503 - val_accuracy: 0.9456\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.1415 - accuracy: 0.9502 - val_loss: 0.1418 - val_accuracy: 0.9501\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.1266 - accuracy: 0.9552 - val_loss: 0.1511 - val_accuracy: 0.9474\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.1151 - accuracy: 0.9596 - val_loss: 0.1286 - val_accuracy: 0.9527\n",
      "313/313 - 1s - loss: 0.1286 - accuracy: 0.9527 - 1s/epoch - 4ms/step\n",
      "7: horse; accuracy: 0.9527000188827515\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.2016 - accuracy: 0.9227 - val_loss: 0.1515 - val_accuracy: 0.9427\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.1410 - accuracy: 0.9470 - val_loss: 0.1236 - val_accuracy: 0.9542\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.1187 - accuracy: 0.9554 - val_loss: 0.1147 - val_accuracy: 0.9589\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.1025 - accuracy: 0.9627 - val_loss: 0.1147 - val_accuracy: 0.9577\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.0917 - accuracy: 0.9668 - val_loss: 0.1084 - val_accuracy: 0.9592\n",
      "313/313 - 1s - loss: 0.1084 - accuracy: 0.9592 - 1s/epoch - 4ms/step\n",
      "8: ship; accuracy: 0.9592000246047974\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.2353 - accuracy: 0.9099 - val_loss: 0.2062 - val_accuracy: 0.9153\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.1692 - accuracy: 0.9353 - val_loss: 0.1500 - val_accuracy: 0.9425\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.1370 - accuracy: 0.9481 - val_loss: 0.1286 - val_accuracy: 0.9500\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.1177 - accuracy: 0.9565 - val_loss: 0.1212 - val_accuracy: 0.9531\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.1043 - accuracy: 0.9616 - val_loss: 0.1177 - val_accuracy: 0.9557\n",
      "313/313 - 1s - loss: 0.1177 - accuracy: 0.9557 - 1s/epoch - 4ms/step\n",
      "9: truck; accuracy: 0.9556999802589417\n"
     ]
    }
   ],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "for c_i, class_name in enumerate(class_names):\n",
    "     train_labels_temp = np.array([1 if num == c_i else 0 for num in train_labels])\n",
    "     test_labels_temp = np.array([1 if num == c_i else 0 for num in test_labels])\n",
    "\n",
    "     # MODEL PREPARATION\n",
    "     model = models.Sequential()\n",
    "     model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "     model.add(layers.MaxPooling2D((2, 2)))\n",
    "     model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "     model.add(layers.MaxPooling2D((2, 2)))\n",
    "     model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "     model.add(layers.Flatten())\n",
    "     model.add(layers.Dense(64, activation='relu'))\n",
    "     model.add(layers.Dense(2))\n",
    "\n",
    "\n",
    "     # compiling\n",
    "     model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "     model.fit(train_images, train_labels_temp, epochs=5, validation_data=(test_images, test_labels_temp))\n",
    "\n",
    "     # results\n",
    "     est_loss, test_acc = model.evaluate(test_images, test_labels_temp, verbose=2)\n",
    "     print(f\"{c_i}: {class_name}; accuracy: {test_acc}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: check metrics change from accuracy to mse"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.5351 - mse: 38.0379 - val_loss: 1.2769 - val_mse: 41.2943\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 23s 14ms/step - loss: 1.1571 - mse: 43.4421 - val_loss: 1.1072 - val_mse: 44.7517\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.0172 - mse: 45.9966 - val_loss: 1.0544 - val_mse: 46.4795\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.9217 - mse: 47.7729 - val_loss: 0.9657 - val_mse: 47.9885\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.8449 - mse: 50.3419 - val_loss: 0.8935 - val_mse: 48.2789\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['mse'])\n",
    "history = model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.8935 - mse: 48.2789 - 1s/epoch - 4ms/step\n",
      "loss: 0.8935045003890991\n"
     ]
    }
   ],
   "source": [
    "est_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"loss: {est_loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}